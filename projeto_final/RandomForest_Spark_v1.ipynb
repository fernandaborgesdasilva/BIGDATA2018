{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaborgesdasilva/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import DecisionTree_entropy\n",
    "import csv\n",
    "from pyspark.sql.types import StringType\n",
    "import random\n",
    "from math import log, sqrt\n",
    "import logging\n",
    "from sklearn import cross_validation\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.addPyFile(\"DecisionTree_entropy.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_rdd(filepath):\n",
    "    rdd = sc.textFile(filepath).mapPartitions(lambda line: csv.reader(line, delimiter=','))\n",
    "    rdd_2 = rdd.map(lambda row: (int(row[0]), row[1], row[2], int(row[3]), row[4],row[5], row[6], row[7], row[8], int(row[9]),int(row[10]), int(row[11]), row[12], row[13]))\n",
    "    rdd_3 = rdd_2.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return rdd_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K\n"
     ]
    }
   ],
   "source": [
    "def test_tree():\n",
    "    data = csv_to_rdd(\"../data/income.csv\").collect()\n",
    "    tree = DecisionTree_entropy.DecisionTreeClassifier(random_features=True)\n",
    "    tree.fit(data)\n",
    "\n",
    "    print(tree.predict([39, 'State-gov', 'Bachelors', 13, 'Never-married',\n",
    "                        'Adm-clerical', 'Not-in-family', 'White', 'Male',\n",
    "                        2174, 0, 40, 'United-States']))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_tree(partition):\n",
    "    final_iterator = []\n",
    "    for sub_list in partition:\n",
    "        final_iterator.append(list(sub_list))\n",
    "    return iter(final_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = csv_to_rdd(\"../data/income.csv\").repartition(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_trees = data.mapPartitionsWithIndex(lambda index, part: (yield index, dataset_tree(part)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, <list_iterator at 0x1a0e4b0a90>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_trees.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "        self.col = col\n",
    "        self.value = value\n",
    "        self.results = results\n",
    "        self.tb = tb\n",
    "        self.fb = fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_random_features(row):\n",
    "    num_features = len(row) - 1\n",
    "    return random.sample(range(num_features), int(sqrt(num_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_subset(row, features_indexes):\n",
    "    return [row[i] for i in features_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_counts(rows):\n",
    "    results = {}\n",
    "    for row in rows:\n",
    "        r = row[len(row) - 1]\n",
    "        if r not in results:\n",
    "            results[r] = 0\n",
    "        results[r] += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(rows):\n",
    "    log2 = lambda x: log(x) / log(2)\n",
    "    results = unique_counts(rows)\n",
    "    ent = 0.0\n",
    "    for r in results.keys():\n",
    "        p = float(results[r]) / len(rows)\n",
    "        ent = ent - p * log2(p)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_set(rows, column, value):\n",
    "    split_function = None\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        split_function = lambda row: row[column] >= value\n",
    "    else:\n",
    "        split_function = lambda row: row[column] == value\n",
    "\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "\n",
    "    return set1, set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(rows,depth):\n",
    "    if len(rows) == 0:\n",
    "        return 0\n",
    "    if depth == 0:\n",
    "        return 1\n",
    "\n",
    "    current_score = entropy(rows)\n",
    "    best_gain = 0.0\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "    column_count = len(rows[0]) - 1\n",
    "\n",
    "    for col in range(0, column_count):\n",
    "        column_values = {}\n",
    "        for row in rows:\n",
    "            column_values[row[col]] = 1\n",
    "        for value in column_values.keys():\n",
    "            set1, set2 = divide_set(rows, col, value)\n",
    "\n",
    "            p = float(len(set1)) / len(rows)\n",
    "            gain = current_score - p * entropy(set1) - (1 - p) * entropy(set2)\n",
    "            if gain > best_gain and len(set1) > 0 and len(set2) > 0:\n",
    "                best_gain = gain\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1, set2)\n",
    "\n",
    "    if best_gain > 0:\n",
    "        trueBranch = build_tree(best_sets[0], depth - 1)\n",
    "        falseBranch = build_tree(best_sets[1], depth - 1)\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_fit(rows):\n",
    "    if len(rows) < 1:\n",
    "        raise ValueError(\"Nao ha amostras suficientes no dataset de entrada.\")\n",
    "\n",
    "    features_indexes = choose_random_features(rows[0])\n",
    "    rows = [get_features_subset(row, features_indexes) + [row[-1]] for row in rows]\n",
    "\n",
    "    return build_tree(rows,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (5, 2),\n",
       " (6, 2),\n",
       " (7, 2),\n",
       " (8, 2),\n",
       " (9, 2),\n",
       " (10, 2),\n",
       " (11, 2),\n",
       " (12, 2),\n",
       " (13, 2),\n",
       " (14, 2),\n",
       " (15, 2),\n",
       " (16, 2),\n",
       " (17, 2),\n",
       " (18, 2),\n",
       " (19, 2),\n",
       " (20, 2),\n",
       " (21, 2),\n",
       " (22, 2),\n",
       " (23, 2),\n",
       " (24, 2),\n",
       " (25, 2),\n",
       " (26, 2),\n",
       " (27, 2),\n",
       " (28, 2),\n",
       " (29, 2),\n",
       " (30, 2),\n",
       " (31, 2),\n",
       " (32, 2),\n",
       " (33, 2),\n",
       " (34, 2),\n",
       " (35, 2),\n",
       " (36, 2),\n",
       " (37, 2),\n",
       " (38, 2),\n",
       " (39, 2),\n",
       " (40, 2),\n",
       " (41, 2),\n",
       " (42, 2),\n",
       " (43, 2),\n",
       " (44, 2),\n",
       " (45, 2),\n",
       " (46, 2),\n",
       " (47, 2),\n",
       " (48, 2),\n",
       " (49, 2),\n",
       " (50, 2),\n",
       " (51, 2),\n",
       " (52, 2),\n",
       " (53, 2),\n",
       " (54, 2),\n",
       " (55, 2),\n",
       " (56, 2),\n",
       " (57, 2),\n",
       " (58, 2),\n",
       " (59, 2)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTree_entropy.DecisionTreeClassifier(max_depth=-1)\n",
    "trees = rdd_trees.reduceByKey(lambda x,y: list(x+y))\n",
    "trees.map(lambda x: (x[0],teste_fit(list(x[1])))).collect()\n",
    "#trees.map(lambda x: (x[0],tree.fit(list(x[1])))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
