{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from math import log, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filepath):\n",
    "    \"\"\"\n",
    "    This function reads the example dataset from a CSV file and returns a\n",
    "    list of lists.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    with open(filepath) as fd:\n",
    "        reader = csv.reader(fd, delimiter=',')\n",
    "\n",
    "        for row in reader:\n",
    "            row = [int(row[0]), row[1], row[2], int(row[3]), row[4],\n",
    "                   row[5], row[6], row[7], row[8], int(row[9]),\n",
    "                   int(row[10]), int(row[11]), row[12], row[13]]\n",
    "            data.append(list(map(lambda x: x.strip() if isinstance(x, str) else x, row)))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "\n",
    "    class DecisionNode:\n",
    "        def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "            self.col = col\n",
    "            self.value = value\n",
    "            self.results = results\n",
    "            self.tb = tb\n",
    "            self.fb = fb\n",
    "\n",
    "    \"\"\"\n",
    "    :param  max_depth:          numero maximo de quebras durante o treinamento\n",
    "    :param  random_features:    Se estiver como Falso, todas a variaveis \n",
    "                                vao ser usadas para treino e predicao, \n",
    "                                senao sera escolhido um conjunto aleatorio \n",
    "                                de tamanho sqrt(nb features)\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=-1, random_features=False):\n",
    "        self.root_node = None\n",
    "        self.max_depth = max_depth\n",
    "        self.features_indexes = []\n",
    "        self.random_features = random_features\n",
    "\n",
    "    def fit(self, rows, criterion=None):\n",
    "        if len(rows) < 1:\n",
    "            raise ValueError(\"Nao ha amostras suficientes no dataset de entrada.\")\n",
    "\n",
    "        if not criterion:\n",
    "            criterion = self.entropy\n",
    "        if self.random_features:\n",
    "            self.features_indexes = self.choose_random_features(rows[0])\n",
    "            rows = [self.get_features_subset(row) + [row[-1]] for row in rows]\n",
    "\n",
    "        self.root_node = self.build_tree(rows, criterion, self.max_depth)\n",
    "\n",
    "    \"\"\"\n",
    "    Retorna uma predicao para as variaveis passadas como parametro\n",
    "    :param  features:   uma lista de valores\n",
    "    \"\"\"\n",
    "    def predict(self, features):\n",
    "        if self.random_features:\n",
    "            if not all(i in range(len(features))\n",
    "                       for i in self.features_indexes):\n",
    "                raise ValueError(\"As variaveis passadas nao batem com o conjunto utilizado para treino\")\n",
    "            features = self.get_features_subset(features)\n",
    "\n",
    "        return self.classify(features, self.root_node)\n",
    "\n",
    "    \"\"\"\n",
    "    Seleciona indices aleatoriamente\n",
    "    \"\"\"\n",
    "    def choose_random_features(self, row):\n",
    "        nb_features = len(row) - 1\n",
    "        return random.sample(range(nb_features), int(sqrt(nb_features)))\n",
    "\n",
    "    \"\"\"\n",
    "    Retorna os valores selecionado randomicamente\n",
    "    \"\"\"\n",
    "    def get_features_subset(self, row):\n",
    "        return [row[i] for i in self.features_indexes]\n",
    "\n",
    "    \"\"\"\n",
    "    Divide o dataset de acordo com o valor do indice da coluna\n",
    "    :param  rows: o dataset\n",
    "    :param  column: o indice da coluna usada para quebrar o dado\n",
    "    :param  value: o valor usado para a quebra\n",
    "    \"\"\"\n",
    "    def divide_set(self, rows, column, value):\n",
    "        split_function = None\n",
    "        if isinstance(value, int) or isinstance(value, float):\n",
    "            split_function = lambda row: row[column] >= value\n",
    "        else:\n",
    "            split_function = lambda row: row[column] == value\n",
    "\n",
    "        set1 = [row for row in rows if split_function(row)]\n",
    "        set2 = [row for row in rows if not split_function(row)]\n",
    "\n",
    "        return set1, set2\n",
    "\n",
    "    \"\"\"\n",
    "    Retorna a ocorrencia de cada resultado\n",
    "    \"\"\"\n",
    "    def unique_counts(self, rows):\n",
    "        results = {}\n",
    "        for row in rows:\n",
    "            r = row[len(row) - 1]\n",
    "            if r not in results:\n",
    "                results[r] = 0\n",
    "            results[r] += 1\n",
    "        return results\n",
    "\n",
    "    \"\"\"\n",
    "    Retorna a entropia das linhas passada como parametro (lista de listas)\n",
    "    \"\"\"\n",
    "    def entropy(self, rows):\n",
    "        log2 = lambda x: log(x) / log(2)\n",
    "        results = self.unique_counts(rows)\n",
    "        ent = 0.0\n",
    "        for r in results.keys():\n",
    "            p = float(results[r]) / len(rows)\n",
    "            ent = ent - p * log2(p)\n",
    "        return ent\n",
    "\n",
    "    \"\"\"\n",
    "    Cria recursivamente a arvore de decisao quebrando o dataset ate que nenhum\n",
    "    ganho de informacao seja adicionado, ou ate que se chegue no maxmio de profundidade\n",
    "    \"\"\"\n",
    "    def build_tree(self, rows, func, depth):\n",
    "        if len(rows) == 0:\n",
    "            return self.DecisionNode()\n",
    "        if depth == 0:\n",
    "            return self.DecisionNode(results=self.unique_counts(rows))\n",
    "\n",
    "        current_score = func(rows)\n",
    "        best_gain = 0.0\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "        column_count = len(rows[0]) - 1\n",
    "\n",
    "        for col in range(0, column_count):\n",
    "            column_values = {}\n",
    "            for row in rows:\n",
    "                column_values[row[col]] = 1\n",
    "            for value in column_values.keys():\n",
    "                set1, set2 = self.divide_set(rows, col, value)\n",
    "\n",
    "                p = float(len(set1)) / len(rows)\n",
    "                gain = current_score - p * func(set1) - (1 - p) * func(set2)\n",
    "                if gain > best_gain and len(set1) > 0 and len(set2) > 0:\n",
    "                    best_gain = gain\n",
    "                    best_criteria = (col, value)\n",
    "                    best_sets = (set1, set2)\n",
    "\n",
    "        if best_gain > 0:\n",
    "            trueBranch = self.build_tree(best_sets[0], func, depth - 1)\n",
    "            falseBranch = self.build_tree(best_sets[1], func, depth - 1)\n",
    "            return self.DecisionNode(col=best_criteria[0],\n",
    "                                     value=best_criteria[1],\n",
    "                                     tb=trueBranch, fb=falseBranch)\n",
    "        else:\n",
    "            return self.DecisionNode(results=self.unique_counts(rows))\n",
    "\n",
    "    \"\"\"\n",
    "    Faz uma predicao usando as variavies passadas como parametro\n",
    "    \"\"\"\n",
    "    def classify(self, observation, tree):\n",
    "        if tree.results is not None:\n",
    "            return list(tree.results.keys())[0]\n",
    "        else:\n",
    "            v = observation[tree.col]\n",
    "            branch = None\n",
    "            if isinstance(v, int) or isinstance(v, float):\n",
    "                if v >= tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            else:\n",
    "                if v == tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            return self.classify(observation, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=50K\n"
     ]
    }
   ],
   "source": [
    "def test_tree():\n",
    "    data = read_csv(\"../data/income.csv\")\n",
    "    tree = DecisionTreeClassifier(random_features=True)\n",
    "    tree.fit(data)\n",
    "\n",
    "    print(tree.predict([39, 'State-gov', 'Bachelors', 13, 'Never-married',\n",
    "                        'Adm-clerical', 'Not-in-family', 'White', 'Male',\n",
    "                        2174, 0, 40, 'United-States']))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForestClassifier(object):\n",
    "\n",
    "    \"\"\"\n",
    "    :param  num_trees: Numero de arvores de decisao\n",
    "    :param  num_samples: Numero de amostras para cada arvore\n",
    "    :param  max_depth: Profundidade maxima da arvore\n",
    "    :param  max_workers: Numero maximo de processos para treinamento\n",
    "    \"\"\"\n",
    "    def __init__(self, num_trees, num_samples, max_depth=-1, max_workers=1):\n",
    "        self.trees = []\n",
    "        self.num_trees = num_trees\n",
    "        self.num_samples = num_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.max_workers = max_workers\n",
    "\n",
    "    def fit(self, data):\n",
    "        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            rand_fts = map(lambda x: [x, random.sample(data, self.num_samples)],range(self.num_trees))\n",
    "            self.trees = list(executor.map(self.train_tree, rand_fts))\n",
    "\n",
    "    \"\"\"\n",
    "    Treina uma unica arvore e a retorna\n",
    "    \"\"\"\n",
    "    def train_tree(self, data):\n",
    "        logging.info('Training tree {}'.format(data[0] + 1))\n",
    "        tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "        tree.fit(data[1])\n",
    "        return tree\n",
    "\n",
    "    def predict(self, feature):\n",
    "        predictions = []\n",
    "\n",
    "        for tree in self.trees:\n",
    "            predictions.append(tree.predict(feature))\n",
    "\n",
    "        return max(set(predictions), key=predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training tree 1\n",
      "INFO:root:Training tree 2\n",
      "INFO:root:Training tree 3\n",
      "INFO:root:Training tree 4\n",
      "INFO:root:Training tree 5\n",
      "INFO:root:Training tree 6\n",
      "INFO:root:Training tree 7\n",
      "INFO:root:Training tree 8\n",
      "INFO:root:Training tree 9\n",
      "INFO:root:Training tree 10\n",
      "INFO:root:Training tree 11\n",
      "INFO:root:Training tree 12\n",
      "INFO:root:Training tree 13\n",
      "INFO:root:Training tree 14\n",
      "INFO:root:Training tree 15\n",
      "INFO:root:Training tree 16\n",
      "INFO:root:Training tree 17\n",
      "INFO:root:Training tree 18\n",
      "INFO:root:Training tree 19\n",
      "INFO:root:Training tree 20\n",
      "INFO:root:Training tree 21\n",
      "INFO:root:Training tree 22\n",
      "INFO:root:Training tree 23\n",
      "INFO:root:Training tree 24\n",
      "INFO:root:Training tree 25\n",
      "INFO:root:Training tree 26\n",
      "INFO:root:Training tree 27\n",
      "INFO:root:Training tree 28\n",
      "INFO:root:Training tree 29\n",
      "INFO:root:Training tree 30\n",
      "INFO:root:Training tree 31\n",
      "INFO:root:Training tree 32\n",
      "INFO:root:Training tree 33\n",
      "INFO:root:Training tree 34\n",
      "INFO:root:Training tree 35\n",
      "INFO:root:Training tree 36\n",
      "INFO:root:Training tree 37\n",
      "INFO:root:Training tree 38\n",
      "INFO:root:Training tree 39\n",
      "INFO:root:Training tree 40\n",
      "INFO:root:Training tree 41\n",
      "INFO:root:Training tree 42\n",
      "INFO:root:Training tree 43\n",
      "INFO:root:Training tree 44\n",
      "INFO:root:Training tree 45\n",
      "INFO:root:Training tree 46\n",
      "INFO:root:Training tree 47\n",
      "INFO:root:Training tree 48\n",
      "INFO:root:Training tree 49\n",
      "INFO:root:Training tree 50\n",
      "INFO:root:Training tree 51\n",
      "INFO:root:Training tree 52\n",
      "INFO:root:Training tree 53\n",
      "INFO:root:Training tree 54\n",
      "INFO:root:Training tree 55\n",
      "INFO:root:Training tree 56\n",
      "INFO:root:Training tree 57\n",
      "INFO:root:Training tree 58\n",
      "INFO:root:Training tree 59\n",
      "INFO:root:Training tree 60\n",
      "INFO:root:Error rate: 13.94206162350292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution took: 303.9595587670001 secs\n"
     ]
    }
   ],
   "source": [
    "def test_rf():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data = read_csv(\"../data/income.csv\")\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "    #rf = RandomForestClassifier(num_trees=60, num_samples=3000, max_workers=4)\n",
    "    rf = RandomForestClassifier(num_trees=60, num_samples=3000, max_workers=1)\n",
    "    rf.fit(train)\n",
    "\n",
    "    errors = 0\n",
    "    features = [ft[:-1] for ft in test]\n",
    "    values = [ft[-1] for ft in test]\n",
    "\n",
    "    for feature, value in zip(features, values):\n",
    "        prediction = rf.predict(feature)\n",
    "        if prediction != value:\n",
    "            errors += 1\n",
    "\n",
    "    logging.info(\"Error rate: {}\".format(errors / len(features) * 100))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    from timeit import default_timer as timer\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    test_rf()\n",
    "    \n",
    "    end = timer()\n",
    "    print('Execution took: %s secs' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
